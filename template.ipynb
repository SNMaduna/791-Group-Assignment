{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project Template\n",
    "\n",
    "**Project Name:** [Your Project Name]\n",
    "\n",
    "**Author(s):** [Your Names]\n",
    "\n",
    "**Date:** [Date]\n",
    "\n",
    "**Description:** [Brief description of the project objectives and goals]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import all necessary libraries and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load the dataset(s) for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# df = pd.read_csv('data/your_dataset.csv')\n",
    "# df = pd.read_excel('data/your_dataset.xlsx')\n",
    "# df = pd.read_json('data/your_dataset.json')\n",
    "\n",
    "# Display basic information\n",
    "# print(f\"Dataset shape: {df.shape}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Perform initial exploration to understand the data structure and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "# missing_values = df.isnull().sum()\n",
    "# missing_percentage = (missing_values / len(df)) * 100\n",
    "# missing_df = pd.DataFrame({\n",
    "#     'Missing Values': missing_values,\n",
    "#     'Percentage': missing_percentage\n",
    "# }).sort_values(by='Missing Values', ascending=False)\n",
    "# print(missing_df[missing_df['Missing Values'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data Types and Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and unique values\n",
    "# for col in df.columns:\n",
    "#     print(f\"{col}: {df[col].dtype}, Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization\n",
    "\n",
    "Create visualizations to understand data patterns and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Distribution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of numerical features\n",
    "# numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "# fig, axes = plt.subplots(nrows=len(numerical_cols)//3 + 1, ncols=3, figsize=(15, 12))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for i, col in enumerate(numerical_cols):\n",
    "#     df[col].hist(bins=30, ax=axes[i], edgecolor='black')\n",
    "#     axes[i].set_title(f'Distribution of {col}')\n",
    "#     axes[i].set_xlabel(col)\n",
    "#     axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "# plt.title('Correlation Heatmap')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features\n",
    "# categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "# for col in categorical_cols:\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     df[col].value_counts().plot(kind='bar')\n",
    "#     plt.title(f'Distribution of {col}')\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel('Count')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n",
    "\n",
    "Clean and prepare the data for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Option 1: Drop rows with missing values\n",
    "# df_cleaned = df.dropna()\n",
    "\n",
    "# Option 2: Fill with mean/median/mode\n",
    "# df['column_name'].fillna(df['column_name'].mean(), inplace=True)\n",
    "\n",
    "# Option 3: Forward fill or backward fill\n",
    "# df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "# df['new_feature'] = df['feature1'] + df['feature2']\n",
    "\n",
    "# Encode categorical variables\n",
    "# df_encoded = pd.get_dummies(df, columns=['categorical_column'])\n",
    "\n",
    "# Or use Label Encoding\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# df['encoded_column'] = le.fit_transform(df['categorical_column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR method\n",
    "# Q1 = df['column_name'].quantile(0.25)\n",
    "# Q3 = df['column_name'].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# outliers = df[(df['column_name'] < lower_bound) | (df['column_name'] > upper_bound)]\n",
    "# print(f\"Number of outliers: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection\n",
    "\n",
    "Select the most relevant features for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# X = df.drop('target_column', axis=1)\n",
    "# y = df['target_column']\n",
    "\n",
    "# Feature selection using correlation\n",
    "# high_corr_features = correlation_matrix['target_column'].abs().sort_values(ascending=False)\n",
    "# print(\"Features ranked by correlation with target:\")\n",
    "# print(high_corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Splitting\n",
    "\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# print(f\"Training set size: {X_train.shape}\")\n",
    "# print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Scaling\n",
    "\n",
    "Normalize or standardize features for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Or use MinMaxScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Building\n",
    "\n",
    "Train and evaluate machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Logistic Regression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "# model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "# y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Advanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Random Forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf_model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "# rf_model.fit(X_train_scaled, y_train)\n",
    "# rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# print(f\"Random Forest Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Gradient Boosting\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# gb_model = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "# gb_model.fit(X_train_scaled, y_train)\n",
    "# gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test, gb_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation\n",
    "\n",
    "Detailed evaluation of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance (for tree-based models)\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'feature': X.columns,\n",
    "#     'importance': rf_model.feature_importances_\n",
    "# }).sort_values('importance', ascending=False)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
    "# plt.title('Top 10 Feature Importances')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "# print(f\"Cross-validation scores: {cv_scores}\")\n",
    "# print(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Hyperparameter Tuning\n",
    "\n",
    "Optimize model parameters for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "#                            param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Comparison\n",
    "\n",
    "Compare multiple models to select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple models\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# models = {\n",
    "#     'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE),\n",
    "#     'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "#     'Random Forest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "#     'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "#     'SVM': SVC(random_state=RANDOM_STATE)\n",
    "# }\n",
    "\n",
    "# results = {}\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train_scaled, y_train)\n",
    "#     pred = model.predict(X_test_scaled)\n",
    "#     accuracy = accuracy_score(y_test, pred)\n",
    "#     results[name] = accuracy\n",
    "#     print(f\"{name}: {accuracy:.4f}\")\n",
    "\n",
    "# # Visualize results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(results.keys(), results.values())\n",
    "# plt.title('Model Comparison')\n",
    "# plt.xlabel('Model')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Results and Insights\n",
    "\n",
    "Summarize findings and key insights from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "\n",
    "1. [Finding 1]\n",
    "2. [Finding 2]\n",
    "3. [Finding 3]\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. [Recommendation 1]\n",
    "2. [Recommendation 2]\n",
    "3. [Recommendation 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Results\n",
    "\n",
    "Save the trained model and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "# import joblib\n",
    "# joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# Save predictions\n",
    "# predictions_df = pd.DataFrame({\n",
    "#     'actual': y_test,\n",
    "#     'predicted': y_pred\n",
    "# })\n",
    "# predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Save results summary\n",
    "# results_summary = pd.DataFrame({\n",
    "#     'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "#     'Value': [accuracy, precision, recall, f1_score]\n",
    "# })\n",
    "# results_summary.to_csv('results_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusion\n",
    "\n",
    "Final thoughts and next steps for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "[Write a brief summary of the entire analysis and its outcomes]\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. [Next step 1]\n",
    "2. [Next step 2]\n",
    "3. [Next step 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
